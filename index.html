<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />

    <title>AI Basketball Shot Angle Detector</title>

    <!-- Tailwind CSS for styling -->

    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Inter font -->
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700;800&display=swap"
      rel="stylesheet"
    />
  </head>
  <body
    class="min-h-screen bg-gradient-to-br from-gray-900 to-gray-700 text-white p-4 flex flex-col items-center justify-center"
  >
    <div
      class="max-w-4xl w-full bg-gray-800 rounded-lg shadow-2xl p-6 space-y-6"
    >
      <h1 class="text-4xl font-extrabold text-center text-blue-400 mb-6">
        Basketball Shot Angle Detector
      </h1>

      <!-- Instructions Section -->
      <div class="bg-gray-700 p-4 rounded-md shadow-inner">
        <button
          id="toggle-instructions"
          class="w-full flex justify-between items-center text-lg font-semibold text-blue-300 hover:text-blue-200 focus:outline-none"
        >
          <span class="flex items-center">
            <svg
              xmlns="http://www.w3.org/2000/svg"
              width="20"
              height="20"
              viewBox="0 0 24 24"
              fill="none"
              stroke="currentColor"
              stroke-width="2"
              stroke-linecap="round"
              stroke-linejoin="round"
              class="lucide lucide-info mr-2"
            >
              <circle cx="12" cy="12" r="10" />
              <path d="M12 16v-4" />
              <path d="M12 8h.01" />
            </svg>
            How to Use
          </span>
          <svg
            id="chevron-icon"
            xmlns="http://www.w3.org/2000/svg"
            width="20"
            height="20"
            viewBox="0 0 24 24"
            fill="none"
            stroke="currentColor"
            stroke-width="2"
            stroke-linecap="round"
            stroke-linejoin="round"
            class="lucide lucide-chevron-down"
          >
            <path d="m6 9 6 6 6-6" />
          </svg>
        </button>
        <div
          id="instructions-content"
          class="mt-4 text-gray-300 text-sm space-y-2"
        >
          <p>
            Click "Upload Video" to select a basketball shot video, OR click
            "Use Camera" for live analysis.
          </p>
          <p>
            2. The video/camera feed will appear below. Click the Play/Pause
            button to control playback.
          </p>
          <p>
            3. As the video plays, The app will attempt to detect a single
            player's right shoulder, elbow and wrist in real-time. If it does,
            it will drawing lines connecting the shoulder, elbow and wrist and
            display the **Elbow Angle** (between upper arm and forearm). It will
            then determine if a boxed area slightly above their wrist is a
            basketball. If a basketball is detected, it will then wait a few
            frames before it's no longer detected and pause the video when this
            occurs. It will determine this to be the **Release Angle** (between
            upper arm and a horizontal line from the shoulder).
            <b
              >Note for this to work properly, there should only be one person
              in the frame with a minimal number of other objects and a clear
              picture of a basketball, preferably taken from the side. The
              person also needs to be releasing the ball with their right
              hand.</b
            >
          </p>
          <p>
            4. When the video pauses, you can click "Log Current Angle" to
            record that specific release angle and timestamp if it's indeed a
            person shooting to maintain a list of release angles.
          </p>
          <p class="font-bold text-yellow-300">
            Note: A possible future feature would be to generate a new video
            file with overlaid annotations. For now, the annotations are shown
            live on the video and you could take screenshots if you're using
            your phone.
          </p>
        </div>
      </div>

      <!-- Video Upload and Controls -->
      <div class="flex flex-col md:flex-row items-center justify-center gap-4">
        <label
          for="video-upload"
          class="cursor-pointer bg-blue-600 hover:bg-blue-700 text-white font-bold py-3 px-6 rounded-full shadow-lg transition duration-300 ease-in-out transform hover:scale-105 flex items-center"
        >
          <svg
            xmlns="http://www.w3.org/2000/svg"
            width="20"
            height="20"
            viewBox="0 0 24 24"
            fill="none"
            stroke="currentColor"
            stroke-width="2"
            stroke-linecap="round"
            stroke-linejoin="round"
            class="lucide lucide-upload-cloud mr-2"
          >
            <path
              d="M4 14.899A7 7 0 1 1 15.71 8h1.79a4.5 4.5 0 0 1 2.5 8.242"
            />
            <path d="M12 12v9" />
            <path d="m16 16-4-4-4 4" />
          </svg>
          Upload Video
        </label>
        <input id="video-upload" type="file" accept="video/*" class="hidden" />

        <button
          id="use-camera-btn"
          class="bg-indigo-600 hover:bg-indigo-700 text-white font-bold py-3 px-6 rounded-full shadow-lg transition duration-300 ease-in-out transform hover:scale-105 flex items-center"
        >
          <svg
            xmlns="http://www.w3.org/2000/svg"
            width="20"
            height="20"
            viewBox="0 0 24 24"
            fill="none"
            stroke="currentColor"
            stroke-width="2"
            stroke-linecap="round"
            stroke-linejoin="round"
            class="lucide lucide-camera mr-2"
          >
            <path
              d="M14.5 4h-5L7 7H4a2 2 0 0 0-2 2v9a2 2 0 0 0 2 2h16a2 2 0 0 0 2-2V9a2 2 0 0 0-2-2h-3l-2.5-3z"
            />
            <circle cx="12" cy="13" r="3" />
          </svg>
          Use Camera
        </button>
        <button
          id="toggle-camera-btn"
          class="bg-gray-600 hover:bg-gray-700 text-white font-bold py-3 px-6 rounded-full shadow-lg transition duration-300 ease-in-out transform hover:scale-105 flex items-center"
          style="display: none"
        >
          <svg
            xmlns="http://www.w3.org/2000/svg"
            width="20"
            height="20"
            viewBox="0 0 24 24"
            fill="none"
            stroke="currentColor"
            stroke-width="2"
            stroke-linecap="round"
            stroke-linejoin="round"
            class="lucide lucide-camera-off mr-2"
          >
            <line x1="2" x2="22" y1="2" y2="22" />
            <path d="M11.66 4H14.5L17 7h3a2 2 0 0 1 2 2v9a2 2 0 0 1-.36.98" />
            <path d="M5.64 5.64A2 2 0 0 0 4 7v9a2 2 0 0 0 2 2h9" />
            <path d="M10.12 10.12A3 3 0 1 0 14 14" />
          </svg>
          <span id="toggle-camera-text">Back Camera</span>
        </button>

        <button
          id="play-pause-btn"
          class="bg-green-600 hover:bg-green-700 text-white font-bold py-3 px-6 rounded-full shadow-lg transition duration-300 ease-in-out transform hover:scale-105 flex items-center"
          style="display: none"
        >
          <svg
            id="play-icon"
            xmlns="http://www.w3.org/2000/svg"
            width="20"
            height="20"
            viewBox="0 0 24 24"
            fill="none"
            stroke="currentColor"
            stroke-width="2"
            stroke-linecap="round"
            stroke-linejoin="round"
            class="lucide lucide-play mr-2"
          >
            <polygon points="5 3 19 12 5 21 5 3" />
          </svg>
          <svg
            id="pause-icon"
            xmlns="http://www.w3.org/2000/svg"
            width="20"
            height="20"
            viewBox="0 0 24 24"
            fill="none"
            stroke="currentColor"
            stroke-width="2"
            stroke-linecap="round"
            stroke-linejoin="round"
            class="lucide lucide-pause mr-2"
            style="display: none"
          >
            <rect x="6" y="4" width="4" height="16" />
            <rect x="14" y="4" width="4" height="16" />
          </svg>
          <span id="play-pause-text">Play</span>
        </button>
        <button
          id="log-angle-btn"
          class="bg-purple-600 hover:bg-purple-700 text-white font-bold py-3 px-6 rounded-full shadow-lg transition duration-300 ease-in-out transform hover:scale-105 flex items-center"
          style="display: none"
        >
          Log Current Angle
        </button>
        <button
          id="reset-btn"
          class="bg-red-600 hover:bg-red-700 text-white font-bold py-3 px-6 rounded-full shadow-lg transition duration-300 ease-in-out transform hover:scale-105 flex items-center"
          style="display: none"
        >
          <svg
            xmlns="http://www.w3.org/2000/svg"
            width="20"
            height="20"
            viewBox="0 0 24 24"
            fill="none"
            stroke="currentColor"
            stroke-width="2"
            stroke-linecap="round"
            stroke-linejoin="round"
            class="lucide lucide-rotate-ccw mr-2"
          >
            <path d="M3 12a9 9 0 1 0 9-9 9.75 9.75 0 0 0-6.76 2.75L3 8" />
            <path d="M3 3v5h5" />
          </svg>
          Reset
        </button>
      </div>

      <!-- Video and Canvas Display Area -->
      <div
        class="video-container rounded-lg shadow-xl border-2 border-blue-500"
      >
        <div id="loading-spinner" class="loading-overlay hidden">
          <div
            class="spinner rounded-full h-16 w-16 border-t-4 border-b-4"
          ></div>
          <p class="ml-4 text-xl text-blue-300">
            Loading video and pose model...
          </p>
        </div>
        <video
          id="video-player"
          playsinline
          muted
          style="display: none"
        ></video>
        <canvas
          id="video-canvas"
          style="max-width: 100%; height: auto"
        ></canvas>
        <!--<canvas id="video-canvas"></canvas>-->
      </div>

      <!-- Angle Display and Log -->
      <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
        <div class="bg-gray-700 p-4 rounded-md shadow-inner">
          <h2 class="text-2xl font-semibold text-blue-300 mb-3">Live Angle</h2>
          <p
            id="current-angle-display"
            class="text-5xl font-bold text-center text-yellow-400"
          >
            N/A
          </p>
        </div>

        <div
          class="bg-gray-700 p-4 rounded-md shadow-inner max-h-64 overflow-y-auto"
        >
          <h2 class="text-2xl font-semibold text-blue-300 mb-3">
            Logged Angles
          </h2>
          <ul id="angles-log-list" class="space-y-2">
            <p id="no-angles-message" class="text-gray-400">
              No angles logged yet.
            </p>
          </ul>
        </div>
      </div>

      <!-- Download Button (with disclaimer) -->
      <div class="text-center mt-6">
        <button
          id="download-btn"
          class="bg-gray-600 hover:bg-gray-700 text-white font-bold py-3 px-6 rounded-full shadow-lg transition duration-300 ease-in-out transform hover:scale-105 flex items-center justify-center mx-auto"
        >
          <svg
            xmlns="http://www.w3.org/2000/svg"
            width="20"
            height="20"
            viewBox="0 0 24 24"
            fill="none"
            stroke="currentColor"
            stroke-width="2"
            stroke-linecap="round"
            stroke-linejoin="round"
            class="lucide lucide-download mr-2"
          >
            <path d="M21 15v4a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2v-4" />
            <polyline points="7 10 12 15 17 10" />
            <line x1="12" x2="12" y1="15" y2="3" />
          </svg>
          Download Annotated Video (Info)
        </button>
      </div>
    </div>

    <!-- MediaPipe Libraries -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose/pose.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <!-- TensorFlow.js and COCO-SSD for Object Detection -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <!--<script
      src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/vision_bundle.js"
      crossorigin="anonymous"
    ></script>-->

    <script type="module">
      // Import necessary modules from MediaPipe Tasks
      import {
        ImageClassifier,
        FilesetResolver,
      } from 'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision/vision_bundle.js';
      // DOM Elements
      const videoUploadInput = document.getElementById('video-upload');
      const videoPlayer = document.getElementById('video-player');
      const videoCanvas = document.getElementById('video-canvas');
      const currentAngleDisplay = document.getElementById(
        'current-angle-display'
      );
      const anglesLogList = document.getElementById('angles-log-list');
      const noAnglesMessage = document.getElementById('no-angles-message');
      const playPauseBtn = document.getElementById('play-pause-btn');
      const useCameraBtn = document.getElementById('use-camera-btn'); // New camera button
      const toggleCameraBtn = document.getElementById('toggle-camera-btn');
      const toggleCameraText = document.getElementById('toggle-camera-text');
      const playIcon = document.getElementById('play-icon');
      const pauseIcon = document.getElementById('pause-icon');
      const playPauseText = document.getElementById('play-pause-text');
      const logAngleBtn = document.getElementById('log-angle-btn');
      const resetBtn = document.getElementById('reset-btn');
      const downloadBtn = document.getElementById('download-btn');
      const loadingSpinner = document.getElementById('loading-spinner');
      const toggleInstructionsBtn = document.getElementById(
        'toggle-instructions'
      );
      const instructionsContent = document.getElementById(
        'instructions-content'
      );
      const chevronIcon = document.getElementById('chevron-icon');

      const ctx = videoCanvas.getContext('2d');

      let pose; // MediaPipe Pose instance
      let classifier; // MediaPipe ImageClassifier instance
      let detector; // COCO-SSD object detection model instance
      let animationFrameId = null; // To store animation frame ID for cleanup
      let currentAngle = null; // Current detected angle
      let currentReleaseAngle = null;
      let anglesLog = []; // Log of angles recorded by the user
      let isPaused = true; // Video playback state
      let isCameraActive = false; // New flag to track camera stream
      let isFrontCamera = true; // Flag to track current camera (true = front, false = back)
      let currentStream = null; // To hold the MediaStream object for camera
      let lastWristPosition = null;
      // #B6655A
      const basketballColors = [
        [255, 165, 0], // Classic orange
        [205, 133, 63], // Burnt Sienna / Darker orange
        [255, 106, 0], // Vibrant orange
        [184, 115, 51], // A more brownish/tan shade
        [150, 100, 50], // Even darker brown-orange
      ]
        .map((color) =>
          Array.from(new Array(color[0]).keys()).map((red) => [
            color[0] - red,
            (color[1] * (color[0] - red)) / color[0],
            (color[2] * (color[0] - red)) / color[0],
          ])
        )
        .flat();
      let approximateBasketballSize = 200; // approximate basketball size by distance from elbow to wrist

      // Stores the current frame's crop information for coordinate transformation
      let currentCropInfo = {
        x: 0,
        y: 0,
        width: 0,
        height: 0,
        scaleX: 1,
        scaleY: 1,
      };

      // Ball Release Detection State
      let isBallHeld = false; // True if ball is currently considered held
      let ballReleaseDetected = false; // True when release is detected
      const basketballConfidenceThreshold = 0.1; // Min confidence for 'basketball' classification
      const releaseDetectionFrames = 1; // Number of frames to check for consistent 'no basketball'
      let framesWithoutBasketball = 0; // Counter for frames without basketball near hand

      // --- Utility Functions ---

      /**
       * Calculates the angle between three points (A, B, C) at point B.
       * Points are objects with x and y properties (e.g., {x: 100, y: 50}).
       * @param {Object} A - First point (e.g., shoulder)
       * @param {Object} B - Middle point (e.g., elbow)
       * @param {Object} C - Third point (e.g., wrist)
       * @returns {number} Angle in degrees.
       */
      function calculateAngle(A, B, C) {
        // Vectors BA and BC
        const BAx = (A.x - B.x) * videoCanvas.width;
        const BAy = (A.y - B.y) * videoCanvas.height;
        const BCx = (C.x - B.x) * videoCanvas.width;
        const BCy = (C.y - B.y) * videoCanvas.height;

        // Dot product of BA and BC
        const dotProduct = BAx * BCx + BAy * BCy;

        // Magnitudes of BA and BC
        const magnitudeBA = Math.sqrt(BAx * BAx + BAy * BAy);
        const magnitudeBC = Math.sqrt(BCx * BCx + BCy * BCy);

        // Cosine of the angle
        let cosAngle = dotProduct / (magnitudeBA * magnitudeBC);

        // Clamp cosAngle to prevent NaN from floating point inaccuracies or values outside [-1, 1]
        cosAngle = Math.max(-1, Math.min(1, cosAngle));

        // Angle in radians, then convert to degrees
        const angleRad = Math.acos(cosAngle);
        const angleDeg = angleRad * (180 / Math.PI);

        return angleDeg;
      }

      /**
       * Updates the angles log display in the UI.
       */
      function updateAnglesLogDisplay() {
        anglesLogList.innerHTML = ''; // Clear existing list
        if (anglesLog.length === 0) {
          noAnglesMessage.style.display = 'block';
        } else {
          noAnglesMessage.style.display = 'none';
          anglesLog.forEach((entry, index) => {
            const listItem = document.createElement('li');
            listItem.className =
              'flex justify-between items-center text-gray-300 bg-gray-600 p-2 rounded-md';
            listItem.innerHTML = `
                        <span>Release Angle: <span class="font-bold text-yellow-300">${entry.releaseAngle}°</span></span>
                        <span>Time: <span class="font-bold text-yellow-300">${entry.timestamp}s</span></span>
                    `;
            anglesLogList.appendChild(listItem);
          });
        }
      }

      /**
       * Hides or shows control buttons based on video presence.
       * @param {boolean} show - True to show, false to hide.
       */
      function toggleControlsVisibility(show) {
        playPauseBtn.style.display = show ? 'flex' : 'none';
        logAngleBtn.style.display = show ? 'flex' : 'none';
        resetBtn.style.display = show ? 'flex' : 'none';
      }

      /**
       * Stops the currently active camera stream, if any.
       */
      function stopCamera() {
        if (currentStream) {
          currentStream.getTracks().forEach((track) => track.stop());
          videoPlayer.srcObject = null;
          isCameraActive = false;
          currentStream = null;
          console.log('Camera stopped.');
        }
      }

      /**
       * Toggles between front and back camera.
       */
      function toggleCamera() {
        isFrontCamera = !isFrontCamera;
        startCamera(isFrontCamera ? 'user' : 'environment');
      }

      /**
       * Starts the camera stream and sets it as video source.
       */
      async function startCamera(facingMode = 'user') {
        stopCamera(); // Stop any existing camera stream or video file

        loadingSpinner.classList.remove('hidden');
        loadingSpinner.querySelector('p').textContent =
          'Requesting camera access...';

        try {
          const stream = await navigator.mediaDevices.getUserMedia({
            video: {
              facingMode: facingMode,
            },
          });
          currentStream = stream;
          videoPlayer.srcObject = stream;
          videoPlayer.play(); // Autoplay camera stream
          isPaused = false;
          isCameraActive = true;
          toggleControlsVisibility(true);
          toggleCameraBtn.style.display = 'flex';
          toggleCameraText.textContent =
            facingMode === 'user' ? 'Back Camera' : 'Front Camera';
          playIcon.style.display = 'none';
          pauseIcon.style.display = 'inline';
          playPauseText.textContent = 'Pause';
          loadingSpinner.classList.add('hidden'); // Hide loading spinner

          // Set canvas dimensions to camera stream dimensions once loaded
          videoPlayer.onloadedmetadata = () => {
            videoCanvas.width = videoPlayer.videoWidth;
            videoCanvas.height = videoPlayer.videoHeight;
            if (!animationFrameId) {
              animationFrameId =
                videoPlayer.requestVideoFrameCallback(processVideoFrame);
            }
          };
        } catch (err) {
          console.error('Error accessing camera: ', err);
          alert(
            'Could not access camera. Please ensure you have a camera connected and have granted permission.'
          );
          loadingSpinner.classList.add('hidden');
          loadingSpinner.querySelector('p').textContent =
            'Error accessing camera.';
          toggleControlsVisibility(false); // Hide controls if camera fails
          toggleCameraBtn.style.display = 'none';
        }
      }

      // --- MediaPipe Processing ---

      /**
       * Callback function when MediaPipe Pose results are available.
       * @param {Object} results - The pose detection results.
       */
      function onResults(results) {
        // Clear the canvas and redraw the video frame to ensure it's always visible
        // want to do this even when there are no results
        // ctx.clearRect(0, 0, videoCanvas.width, videoCanvas.height);
        // ctx.drawImage(videoPlayer, 0, 0, videoCanvas.width, videoCanvas.height);

        if (results.poseLandmarks) {
          // Draw the pose landmarks and connections on the canvas
          // Green color for connections, Red for landmarks
          // MediaPipe's drawing_utils are available globally after CDN import
          const connectionIndices = [
            POSE_LANDMARKS.RIGHT_SHOULDER,
            POSE_LANDMARKS.RIGHT_ELBOW,
            POSE_LANDMARKS.RIGHT_INDEX,
          ];
          const landmarksToDraw = results.poseLandmarks.filter((_, index) =>
            connectionIndices.includes(index)
          );

          const shoulderYWristX = {
            x: landmarksToDraw[2].x,
            y: landmarksToDraw[0].y,
            z: landmarksToDraw[0].z,
          };

          // Identify key points for the right arm (assuming right-handed shot)
          const rightShoulder =
            results.poseLandmarks[POSE_LANDMARKS.RIGHT_SHOULDER];
          const rightElbow = results.poseLandmarks[POSE_LANDMARKS.RIGHT_ELBOW];
          const rightWrist = results.poseLandmarks[POSE_LANDMARKS.RIGHT_INDEX];
          let currentWristPosition = null;
          const belowShoulderToWrist = [rightShoulder, shoulderYWristX];

          if (window.drawConnectors && window.drawLandmarks && window.Pose) {
            window.drawConnectors(
              ctx,
              landmarksToDraw,
              //.map(({ x, y }) => ({ x, y })),
              window.POSE_CONNECTIONS,
              {
                color: '#00FF00',
                lineWidth: Math.max(
                  Math.round(
                    (4 * videoPlayer.videoWidth) /
                      videoCanvas.getBoundingClientRect().width
                  ),
                  4
                ),
              }
            );
            // draw horizontal line from shoulder to below elbow
            window.drawConnectors(
              ctx,
              belowShoulderToWrist,
              //.map(({ x, y }) => ({ x, y })),
              window.POSE_CONNECTIONS,
              {
                color: '#00FF00',
                lineWidth: Math.max(
                  Math.round(
                    (4 * videoPlayer.videoWidth) /
                      videoCanvas.getBoundingClientRect().width
                  ),
                  4
                ),
              }
            );
            window.drawLandmarks(
              ctx,
              landmarksToDraw.concat(belowShoulderToWrist),
              //.map(({ x, y }) => ({ x, y })),
              {
                color: '#FF0000',
                lineWidth: Math.max(
                  2,
                  (2 * videoPlayer.videoWidth) /
                    videoCanvas.getBoundingClientRect().width
                ),
              }
            );

            // Check if all necessary landmarks are detected for the right arm with sufficient visibility
            if (
              rightShoulder &&
              rightElbow &&
              rightWrist &&
              rightShoulder.visibility > 0.5 &&
              rightElbow.visibility > 0.5 &&
              rightWrist.visibility > 0.5
            ) {
              // Calculate the angle between upper arm (shoulder-elbow) and forearm (elbow-wrist)
              const angle = calculateAngle(
                rightShoulder,
                rightElbow,
                rightWrist
              );
              currentAngle = angle.toFixed(2); // Update current angle state with 2 decimal places
              currentAngleDisplay.textContent = `${currentAngle}°`;
              currentWristPosition = { x: rightWrist.x, y: rightWrist.y };

              approximateBasketballSize =
                Math.max(
                  Math.round(
                    Math.sqrt(
                      ((rightElbow.x - rightWrist.x) *
                        videoPlayer.videoWidth) **
                        2 +
                        ((rightElbow.y - rightWrist.y) *
                          videoPlayer.videoHeight) **
                          2
                    )
                  ),
                  10
                ) || 200;

              // Draw the angle text on the canvas near the elbow
              ctx.font = `${Math.max(
                Math.floor(
                  (30 * videoPlayer.videoWidth) /
                    videoCanvas.getBoundingClientRect().width
                ),
                30
              )}px Arial`;

              ctx.fillStyle = 'yellow';
              // Position text relative to canvas size and elbow coordinates
              ctx.fillText(
                `Angle: ${currentAngle}°`,
                rightElbow.x * videoCanvas.width + 10,
                rightElbow.y * videoCanvas.height - 10
              );

              // If basketball is currently "held", draw an ORANGE circle around the wrist
              if (isBallHeld) {
                /*console.log(
                  'ISBALL',
                  rightWrist.x *
                    (videoPlayer.videoWidth ** 2 /
                      videoCanvas.getBoundingClientRect().width),
                  rightWrist.y *
                    (videoPlayer.videoHeight ** 2 /
                      videoCanvas.getBoundingClientRect().height),
                  videoCanvas.width,
                  videoCanvas.getBoundingClientRect().width,
                  videoPlayer.videoWidth,
                  rightWrist.x *
                    (videoCanvas.getBoundingClientRect().width /
                      videoPlayer.videoWidth)
                );*/

                ctx.beginPath();
                ctx.arc(
                  rightWrist.x * videoPlayer.videoWidth,
                  rightWrist.y * videoPlayer.videoHeight,
                  //transformedLandmarksForDrawing[POSE_LANDMARKS.RIGHT_WRIST].y,
                  Math.max(
                    20,
                    Math.round(
                      (20 * videoPlayer.videoWidth) /
                        videoCanvas.getBoundingClientRect().width
                    )
                  ), // Radius
                  0,
                  2 * Math.PI
                );
                ctx.strokeStyle = 'orange'; // Changed to orange
                ctx.lineWidth = 5;
                ctx.stroke();
                ctx.fillStyle = 'orange'; // Changed to orange

                ctx.font = `${Math.max(
                  Math.floor(
                    (30 * videoPlayer.videoWidth) /
                      videoCanvas.getBoundingClientRect().width
                  ),
                  30
                )}px Arial`;

                // Position text relative to canvas size and elbow coordinates
                ctx.fillText(
                  'Ball Released',
                  rightWrist.x * videoCanvas.width + 25,
                  rightWrist.y * videoCanvas.height + 10
                );

                // Calculate the angle between upper arm (shoulder-elbow) and forearm (elbow-wrist)
                const releaseAngle = calculateAngle(
                  shoulderYWristX,
                  rightShoulder,
                  rightElbow
                );
                currentReleaseAngle = releaseAngle.toFixed(2); // Update current angle state with 2 decimal places
                // currentAngleDisplay.textContent = `${currentAngle}°`;

                // Draw the angle text on the canvas near the elbow
                ctx.font = `${Math.max(
                  Math.floor(
                    (30 * videoPlayer.videoWidth) /
                      videoCanvas.getBoundingClientRect().width
                  ),
                  30
                )}px Arial`;

                ctx.fillStyle = 'yellow';
                // Position text relative to canvas size and elbow coordinates
                ctx.fillText(
                  `Release Angle: ${currentReleaseAngle}°`,
                  rightElbow.x * videoCanvas.width + 10,
                  rightElbow.y * videoCanvas.height + 70
                );
              }

              // Update last wrist position if valid pose was detected
              if (
                currentWristPosition &&
                currentWristPosition.y < rightShoulder.y
              ) {
                lastWristPosition = currentWristPosition;
              } else {
                lastWristPosition = null; // Clear if wrist is not detected
              }
              /*
              if (true /* condition to be added later ) {
                // Calculate the angle between upper arm (shoulder-elbow) and forearm (elbow-wrist)
                const releaseAngle = calculateAngle(
                  shoulderYWristX,
                  rightShoulder,
                  rightElbow
                );
                const currentReleaseAngle = releaseAngle.toFixed(2); // Update current angle state with 2 decimal places
                // currentAngleDisplay.textContent = `${currentAngle}°`;

                // Draw the angle text on the canvas near the elbow
                ctx.font = `${Math.max(
                  Math.floor(
                    (30 * videoPlayer.videoWidth) /
                      videoCanvas.getBoundingClientRect().width
                  ),
                  30
                )}px Arial`;

                ctx.fillStyle = 'yellow';
                // Position text relative to canvas size and elbow coordinates
                ctx.fillText(
                  `Release Angle: ${currentReleaseAngle}°`,
                  rightElbow.x * videoCanvas.width + 10,
                  rightElbow.y * videoCanvas.height + 70
                );
              }*/
            } else {
              currentAngle = null; // No valid arm detected or confidence too low
              currentAngleDisplay.textContent = 'N/A';
            }
          }
        } else {
          currentAngle = null; // No pose detected in the frame
          currentAngleDisplay.textContent = 'N/A';
        }
      }

      function colorDistance(c1, c2) {
        return Math.sqrt(
          Math.pow(c1[0] - c2[0], 2) +
            Math.pow(c1[1] - c2[1], 2) +
            Math.pow(c1[2] - c2[2], 2)
        );
      }

      /**
       * A simple region growing algorithm to find pixels of similar color/brightness.
       * @param {ImageData} imageData The image data to process.
       * @param {number} startX The starting X coordinate.
       * @param {number} startY The starting Y coordinate.
       * @param {number} tolerance The color/brightness tolerance.
       * @returns {Object} An object with `pixels` array and `bounds` object.
       */
      function regionGrow(imageData, startX, startY, tolerance) {
        const width = imageData.width;
        const height = imageData.height;
        const data = imageData.data;
        const seedColor = getPixelColor(data, startX, startY, width);
        const visited = new Uint8Array(width * height);
        const stack = [{ x: startX, y: startY }];
        const regionPixels = [];
        const bounds = {
          minX: startX,
          minY: startY,
          maxX: startX,
          maxY: startY,
        };

        function getPixelColor(data, x, y, width) {
          const i = (y * width + x) * 4;
          return [data[i], data[i + 1], data[i + 2]];
        }

        while (stack.length > 0) {
          const p = stack.pop();
          const x = p.x;
          const y = p.y;
          const i = y * width + x;

          if (x < 0 || x >= width || y < 0 || y >= height || visited[i])
            continue;

          const currentColor = getPixelColor(data, x, y, width);
          //if (colorDistance(seedColor, currentColor) <= tolerance) {
          /*          const basketballColors = [
            [255, 165, 0], // Classic orange
            [205, 133, 63], // Burnt Sienna / Darker orange
            [255, 106, 0], // Vibrant orange
            [184, 115, 51], // A more brownish/tan shade
            [150, 100, 50], // Even darker brown-orange
          ]
            .map((color) =>
              Array.from(new Array(color[0]).keys()).map((red) => [
                color[0] - red,
                (color[1] * (color[0] - red)) / color[0],
                (color[2] * (color[0] - red)) / color[0],
              ])
            )
            .flat();*/
          //console.log(basketballColors);
          /*   basketballColors.map((bballColor) =>
              colorDistance(bballColor, currentColor)
            )
          );*/

          if (
            basketballColors.some(
              (bballColor) => colorDistance(bballColor, currentColor) <= 30
            )
          ) {
            // if (currentColor[0] - 5 > currentColor[1] && currentColor[2] < 127) {
            // use for orangish
            visited[i] = 1;
            regionPixels.push({ x, y });

            // Update bounds
            bounds.minX = Math.min(bounds.minX, x);
            bounds.minY = Math.min(bounds.minY, y);
            bounds.maxX = Math.max(bounds.maxX, x);
            bounds.maxY = Math.max(bounds.maxY, y);

            // Add neighbors to stack
            for (let i = 1; i < 8; i++) {
              stack.push({ x: x + i, y });
              stack.push({ x: x - i, y });
              stack.push({ x, y: y + i });
              stack.push({ x, y: y - i });
            }
          }
        }
        return { pixels: regionPixels, bounds };
      }

      function getAllOrangish(
        imageData,
        expandOut = Math.floor(approximateBasketballSize / 20),
        tolerance = 30
      ) {
        const width = imageData.width;
        const height = imageData.height;
        const data = imageData.data;
        const regionPixels = [];
        const bounds = {
          minX: Infinity,
          minY: Infinity,
          maxX: -Infinity,
          maxY: -Infinity,
        };

        function getPixelColor(data, x, y, width) {
          const i = (y * width + x) * 4;
          return [data[i], data[i + 1], data[i + 2]];
        }

        for (let x = 0; x < width; x++) {
          for (let y = 0; y < height; y++) {
            const currentColor = getPixelColor(data, x, y, width);
            if (
              currentColor[0] - 50 > currentColor[1] ||
              basketballColors.some(
                (bballColor) => colorDistance(bballColor, currentColor) <= 0
              )
            ) {
              for (let r = -expandOut; r < expandOut; r++) {
                for (let c = -expandOut; c < expandOut; c++) {
                  if (
                    x + c < width &&
                    x + c >= 0 &&
                    y + r >= 0 &&
                    y + r < height
                  ) {
                    regionPixels[x + c] = regionPixels[x + c] || [];
                    if (!regionPixels[x + c].includes(y + r)) {
                      regionPixels[x + c].push(y + r);
                      // Update bounds
                      bounds.minX = Math.min(bounds.minX, x + c);
                      bounds.minY = Math.min(bounds.minY, y + r);
                      bounds.maxX = Math.max(bounds.maxX, x + c);
                      bounds.maxY = Math.max(bounds.maxY, y + r);
                    }
                  }
                }
              }
            }
          }
        }

        return {
          pixels: regionPixels.map((ys, x) => ys.map((y) => ({ x, y }))).flat(),
          bounds,
        };
        /*
         if (
              basketballColors.some(
                (bballColor) => colorDistance(bballColor, currentColor) <= 30
              )
            ) {
              // if (currentColor[0] - 5 > currentColor[1] && currentColor[2] < 127) {
              // use for orangish
              visited[i] = 1;
              regionPixels.push({ x, y });

              // Update bounds
              bounds.minX = Math.min(bounds.minX, x);
              bounds.minY = Math.min(bounds.minY, y);
              bounds.maxX = Math.max(bounds.maxX, x);
              bounds.maxY = Math.max(bounds.maxY, y);

              // Add neighbors to stack
              for (let i = 1; i < 8; i++) {
                stack.push({ x: x + i, y });
                stack.push({ x: x - i, y });
                stack.push({ x, y: y + i });
                stack.push({ x, y: y - i });
              }
            }
          }
          return { pixels: regionPixels, bounds };
        }
        */
      }

      /**
       * Finds the longest vertical and horizontal line segments within a region of pixels.
       * @param {Array<Object>} pixels An array of pixel objects with x, y properties.
       * @returns {Object} An object with lengths of the longest vertical and horizontal lines.
       */
      function findLongestLines(pixels) {
        const pixelSet = new Set(pixels.map((p) => `${p.x},${p.y}`));
        let maxHorizontal = 0;
        let maxVertical = 0;
        const visited = new Set();

        // Horizontal scan
        for (const p of pixels) {
          if (visited.has(`${p.x},${p.y}`)) continue;
          let currentLength = 0;
          let x = p.x;
          while (pixelSet.has(`${x},${p.y}`)) {
            visited.add(`${x},${p.y}`);
            currentLength++;
            x++;
          }
          maxHorizontal = Math.max(maxHorizontal, currentLength);
        }

        // Vertical scan
        visited.clear();
        for (const p of pixels) {
          if (visited.has(`${p.x},${p.y}`)) continue;
          let currentLength = 0;
          let y = p.y;
          while (pixelSet.has(`${p.x},${y}`)) {
            visited.add(`${p.x},${y}`);
            currentLength++;
            y++;
          }
          maxVertical = Math.max(maxVertical, currentLength);
        }

        return { maxHorizontal, maxVertical };
      }

      /**
       * Finds a pixel within the imageData that falls within a given color range.
       * @param {ImageData} imageData The image data to search.
       * @param {Array<number>} targetColor RGB color to match (e.g., [255, 165, 0] for orange).
       * @param {number} tolerance Color tolerance for the match (Euclidean distance).
       * @returns {Object|null} An object with x and y coordinates, or null if no match is found.
       */
      function findSeedPixel(imageData, targetColor, tolerance) {
        const data = imageData.data;
        const width = imageData.width;
        const height = imageData.height;
        const [tr, tg, tb] = targetColor;

        for (let y = height - 1; y >= 0; y--) {
          for (let x = 0; x < width; x++) {
            const i = (y * width + x) * 4;
            const currentColor = [data[i], data[i + 1], data[i + 2]];

            if (
              basketballColors.some(
                (bballColor) => colorDistance(bballColor, currentColor) <= 30
              )
            ) {
              return { x, y };
            }
          }
        }
        return null;
      }

      /**
       * The new function to perform the geometric check for a basketball.
       * @param {HTMLCanvasElement} canvas The canvas element with the video frame.
       * @param {Object} wristPoint The normalized wrist coordinates.
       * @returns {boolean} True if a basketball is likely detected, false otherwise.
       */
      function geometricBasketballCheck(
        canvas,
        wristPoint,
        cropSize = approximateBasketballSize
      ) {
        if (!wristPoint) return false;

        const videoWidth = videoPlayer.videoWidth;
        const videoHeight = videoPlayer.videoHeight;
        const ctx = canvas.getContext('2d');

        // Define the square region above the wrist
        // const cropSize = 200;
        const wristX = wristPoint.x * videoWidth;
        const wristY = wristPoint.y * videoHeight;
        const cropX = Math.max(0, wristX - cropSize / 2);
        const cropY = Math.max(0, wristY - cropSize - 5);
        const actualCropWidth = Math.min(cropSize, videoWidth - cropX);
        const actualCropHeight = Math.min(cropSize, videoHeight - cropY);

        if (actualCropWidth <= 0 || actualCropHeight <= 0) {
          //geometricCheckStatus.textContent = 'N/A';
          return false;
        }

        const imageData = ctx.getImageData(
          cropX,
          cropY,
          actualCropWidth,
          actualCropHeight
        );

        // Find a seed point for region growing (center of the crop)
        const orangeSeedPoint = findSeedPixel(imageData, [255, 165, 0], 30); // Tolerance of 50
        const seedX = orangeSeedPoint?.x || Math.floor(actualCropWidth / 2);
        const seedY =
          orangeSeedPoint?.y || Math.floor((3 / 4) * actualCropHeight);

        // Perform region growing
        // The tolerance and expand factor can be tuned for better results
        // const region = regionGrow(imageData, seedX, seedY, 30); // Tolerance of 30
        const region = getAllOrangish(imageData);

        //console.log(region);
        //debugger;

        const outlineWidth = region.bounds.maxX - region.bounds.minX;
        const outlineHeight = region.bounds.maxY - region.bounds.minY;
        ctx.strokeStyle = 'teal'; // Green outline
        ctx.lineWidth = 5;
        // Add the crop offsets to the region bounds for correct positioning on the main canvas
        ctx.strokeRect(
          cropX + region.bounds.minX,
          cropY + region.bounds.minY,
          outlineWidth,
          outlineHeight
        );
        ctx.fillStyle = 'purple';
        console.log(canvas, region.pixels);
        region.pixels.forEach((px) =>
          ctx.fillRect(cropX + px.x, cropY + px.y, 1, 1)
        );
        ctx.fillStyle = 'red';
        //debugger;
        // If the region is too small, it's probably not a basketball
        if (region.pixels.length < 100) {
          //geometricCheckStatus.textContent = 'Too small';
          return false;
        }

        // Find the longest vertical and horizontal line segments in the grown region
        const { maxHorizontal, maxVertical } = findLongestLines(region.pixels);

        // Check if the lengths are sufficiently large and close to each other
        const minSize = 100; // Minimum pixel size for a basketball
        const aspectRatioTolerance = 0.2; // 20% tolerance for aspect ratio (0.8 to 1.2)

        const aspectRatio = maxVertical / maxHorizontal;
        const isSufficientlyLarge =
          maxHorizontal >= minSize && maxVertical >= minSize;
        const isSufficientlyCircular =
          aspectRatio >= 1 - aspectRatioTolerance &&
          aspectRatio <= 1 + aspectRatioTolerance;

        console.log(cropY + region.bounds.maxY, wristY);
        const isSufficientlyCloseToWrist =
          cropY + region.bounds.maxY >= wristY - 5;

        // Log the status for debugging
        if (
          isSufficientlyLarge &&
          isSufficientlyCircular &&
          isSufficientlyCloseToWrist
        ) {
          //geometricCheckStatus.textContent = '✔ Confirmed';
          //geometricCheckStatus.style.color = 'lime';
          return true;
        } else {
          //geometricCheckStatus.textContent = '❌ Failed';
          //geometricCheckStatus.style.color = 'red';
          return false;
        }
      }

      /**
       * Processes each video frame for pose detection.
       * This function is called recursively using requestVideoFrameCallback.
       */
      async function processVideoFrame() {
        if (
          !videoPlayer ||
          videoPlayer.paused ||
          videoPlayer.ended ||
          !pose ||
          !detector
        ) {
          animationFrameId = null; // Stop the loop
          return;
        }

        // Perform pose detection on the current video frame
        // MediaPipe Pose expects an HTMLVideoElement
        try {
          ctx.clearRect(0, 0, videoCanvas.width, videoCanvas.height);
          ctx.drawImage(
            videoPlayer,
            0,
            0,
            videoCanvas.width,
            videoCanvas.height
          );

          /*
          const predictions = await detector.detect(videoPlayer);
          // Find the most confident 'sports ball' (which includes basketballs)
          const basketballPrediction = predictions.find(
            (p) => p.class === 'sports ball' && p.score > 0
          );
          // console.log('PREDICTIONS', predictions);
          if (basketballPrediction) {
            console.log('BASKETBALL', basketballPrediction);
            togglePause();
            // Draw bounding box of basketball for visualization
            ctx.strokeStyle = 'lime';
            ctx.lineWidth = 4;
            // Scale bbox coordinates to main canvas dimensions
            const [bballX, bballY, bballWidth, bballHeight] =
              basketballPrediction.bbox;
            const scaledX =
              bballX * (videoCanvas.width / videoPlayer.videoWidth);
            const scaledY =
              bballY * (videoCanvas.height / videoPlayer.videoHeight);
            const scaledWidth =
              bballWidth * (videoCanvas.width / videoPlayer.videoWidth);
            const scaledHeight =
              bballHeight * (videoCanvas.height / videoPlayer.videoHeight);
            console.log(scaledX, scaledY, scaledWidth, scaledHeight);
            ctx.strokeRect(scaledX, scaledY, scaledWidth, scaledHeight);
          }
          */

          await pose.send({ image: videoPlayer });
        } catch (error) {
          console.error('Error sending image to MediaPipe Pose:', error);
          // Optionally, stop processing or show an error message to the user
        }

        // Now, perform image classification to detect basketball near the hand
        let basketballDetectedThisFrame = false;
        if (lastWristPosition && POSE_LANDMARKS) {
          // Define a region around the wrist for classification
          // Convert normalized wrist position to pixel coordinates
          const wristX = lastWristPosition.x * videoPlayer.videoWidth;
          const wristY = lastWristPosition.y * videoPlayer.videoHeight;

          // Define a square region around the wrist (e.g., 200x200 pixels)
          const cropSize = approximateBasketballSize; // Increased crop size to capture the ball better
          const cropX = Math.max(0, wristX - cropSize / 2);
          const cropY = Math.max(0, wristY - cropSize);
          const actualCropWidth = Math.min(
            cropSize,
            videoPlayer.videoWidth - cropX
          );
          const actualCropHeight = Math.min(
            cropSize,
            videoPlayer.videoHeight - cropY
          );

          if (actualCropWidth > 0 && actualCropHeight > 0) {
            videoCanvas
              .getContext('2d')
              .strokeRect(cropX, cropY, actualCropWidth, actualCropHeight);
            const tempCanvas = document.createElement('canvas');
            const tempCtx = tempCanvas.getContext('2d');
            tempCanvas.width = actualCropWidth;
            tempCanvas.height = actualCropHeight;

            // Draw the cropped region of the video onto the temporary canvas
            tempCtx.drawImage(
              videoPlayer,
              cropX,
              cropY,
              actualCropWidth,
              actualCropHeight, // Source rectangle
              0,
              0,
              actualCropWidth,
              actualCropHeight // Destination rectangle
            );

            // Perform classification on the cropped image
            const classifications = classifier.classify(tempCanvas);

            if (classifications && classifications.classifications.length > 0) {
              const categories = classifications.classifications[0].categories;
              const basketballCategory = categories.find(
                (cat) => cat.categoryName === 'basketball'
              );
              /*console.log(
                basketballCategory,
                categories.slice().sort((x, y) => y.score - x.score),
                categories
                  .slice()
                  .sort((x, y) => y.score - x.score)
                  .slice(0, 20)
                  .map((cat) => cat.categoryName)
              );*/

              if (
                geometricBasketballCheck(videoCanvas, lastWristPosition) ||
                (basketballCategory &&
                  categories
                    .slice()
                    .sort((x, y) => y.score - x.score)
                    .slice(0, 20)
                    .find((cat) => cat.categoryName === 'basketball') &&
                  basketballCategory.score > basketballConfidenceThreshold)
              ) {
                basketballDetectedThisFrame = true;
                console.log('basketball detected');
              }
            }
          }
        }

        // --- Ball Release Detection Logic ---
        if (!videoPlayer.paused && ballReleaseDetected) {
          // If video was paused by release and now playing, reset flags
          ballReleaseDetected = false;
          isBallHeld = false;
          framesWithoutBasketball = 0;
        }

        if (basketballDetectedThisFrame) {
          isBallHeld = true;
          framesWithoutBasketball = 0; // Reset counter if basketball is detected
        } else {
          if (isBallHeld) {
            framesWithoutBasketball++;
            if (framesWithoutBasketball >= releaseDetectionFrames) {
              // Basketball was held, and now consistently not detected for several frames
              if (!ballReleaseDetected) {
                ballReleaseDetected = true;
                isBallHeld = false;
                //if (currentReleaseAngle) {
                togglePause();
                console.log(
                  `Ball released at ${videoPlayer.currentTime.toFixed(
                    2
                  )}s! Pausing video.`
                );
                //}
                // Log angles automatically on release
                /*if (
                  currentElbowAngle !== null &&
                  currentReleaseAngle !== null
                ) {
                  anglesLog.push({
                    elbowAngle: currentElbowAngle,
                    releaseAngle: currentReleaseAngle,
                    timestamp: videoPlayer.currentTime.toFixed(2),
                  });
                  updateAnglesLogDisplay();
                }*/
              }
            }
          } else {
            // If ball was never held, just keep counter at 0
            framesWithoutBasketball = 0;
          }
        }

        // Request the next frame callback to continue the loop
        animationFrameId =
          videoPlayer.requestVideoFrameCallback(processVideoFrame);
      }

      /**
       * Initializes the MediaPipe Pose model.
       */
      async function initializePose() {
        // Initialize MediaPipe Image Classifier
        const vision = await FilesetResolver.forVisionTasks(
          'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'
        );
        classifier = await ImageClassifier.createFromOptions(vision, {
          baseOptions: {
            // Corrected modelAssetPath
            modelAssetPath:
              'https://storage.googleapis.com/mediapipe-models/image_classifier/efficientnet_lite0/int8/1/efficientnet_lite0.tflite',
          },
          runningMode: 'IMAGE', // Use IMAGE mode for classifying cropped frames
        });

        if (window.Pose) {
          // Check if MediaPipe Pose is loaded globally
          pose = new window.Pose({
            locateFile: (file) => {
              return `https://cdn.jsdelivr.net/npm/@mediapipe/pose/${file}`;
            },
          });

          pose.setOptions({
            modelComplexity: 1, // Can be 0, 1, or 2. Higher is more accurate but slower.
            smoothLandmarks: true, // Smooths landmark positions across frames
            enableSegmentation: false, // Disables segmentation mask generation (not needed here)
            smoothSegmentation: false, // Disables smoothing for segmentation
            minDetectionConfidence: 0.5, // Minimum confidence for a pose detection to be considered successful
            minTrackingConfidence: 0.5, // Minimum confidence for a pose landmark to be tracked successfully
          });

          pose.onResults(onResults);

          if (window.cocoSsd && window.tf) {
            detector = await window.cocoSsd.load();
          } else {
            throw new Error('TensorFlow.js or COCO-SSD library not loaded.');
          }
        } else {
          console.error(
            'MediaPipe Pose library not loaded. Check CDN script tags.'
          );
        }
      }

      /*
      async function initializeObjectDetection() {
        const vision = await FilesetResolver.forVisionTasks(
          // path/to/wasm/root
          'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm'
        );
        objectDetector = await ObjectDetector.createFromOptions(vision, {
          baseOptions: {
            modelAssetPath: `https://storage.googleapis.com/mediapipe-tasks/object_detector/efficientdet_lite0_uint8.tflite`,
          },
          scoreThreshold: 0.5,
          runningMode: 'video',
        });
      }
      */

      function togglePause() {
        if (videoPlayer.paused) {
          videoPlayer.play();
          isPaused = false;
          playIcon.style.display = 'none';
          pauseIcon.style.display = 'inline';
          playPauseText.textContent = 'Pause';
          // Start processing if not already running
          if (!animationFrameId) {
            animationFrameId =
              videoPlayer.requestVideoFrameCallback(processVideoFrame);
          }
        } else {
          videoPlayer.pause();
          isPaused = true;
          playIcon.style.display = 'inline';
          pauseIcon.style.display = 'none';
          playPauseText.textContent = 'Play';
          // Cancel processing if paused
          if (animationFrameId) {
            videoPlayer.cancelVideoFrameCallback(animationFrameId);
            animationFrameId = null;
          }
        }
      }

      // --- Event Listeners ---

      // Handle video file upload
      videoUploadInput.addEventListener('change', (event) => {
        const file = event.target.files[0];
        stopCamera(); // Stop camera if active
        toggleCameraBtn.style.display = 'none';
        if (file) {
          // Revoke previous object URL if it exists to free up memory
          if (videoPlayer.src) {
            URL.revokeObjectURL(videoPlayer.src);
          }
          const url = URL.createObjectURL(file);
          videoPlayer.src = url;
          anglesLog = []; // Clear previous angle log
          currentAngle = null; // Clear current angle display
          currentAngleDisplay.textContent = 'N/A';
          isPaused = true; // Pause video on new upload
          updateAnglesLogDisplay(); // Clear log display
          toggleControlsVisibility(true); // Show controls
          loadingSpinner.classList.remove('hidden'); // Show loading spinner
        }
      });

      // Handle Use Camera button click
      useCameraBtn.addEventListener('click', startCamera);

      // Handle Toggle Camera button click
      toggleCameraBtn.addEventListener('click', toggleCamera);

      // When video metadata is loaded (duration, dimensions etc.)
      videoPlayer.addEventListener('loadedmetadata', () => {
        videoCanvas.width = videoPlayer.videoWidth;
        videoCanvas.height = videoPlayer.videoHeight;
        loadingSpinner.classList.add('hidden'); // Hide loading spinner
        // Start processing loop only if not paused
        if (!isPaused) {
          if (animationFrameId) {
            videoPlayer.cancelVideoFrameCallback(animationFrameId);
          }
          animationFrameId =
            videoPlayer.requestVideoFrameCallback(processVideoFrame);
        }
      });

      // When video data is loaded and ready to play
      videoPlayer.addEventListener('loadeddata', () => {
        loadingSpinner.classList.add('hidden'); // Ensure loading spinner is hidden
        console.log('Video data ready');
        videoPlayer.currentTime = 0;
      });

      videoPlayer.addEventListener('seeked', () => {
        // Draw the current video frame onto the canvas
        ctx.clearRect(0, 0, videoCanvas.width, videoCanvas.height);
        ctx.drawImage(videoPlayer, 0, 0, videoCanvas.width, videoCanvas.height);
      });

      // When video is buffering
      videoPlayer.addEventListener('waiting', () => {
        loadingSpinner.classList.remove('hidden'); // Show loading spinner
      });

      // When video starts playing after buffering
      videoPlayer.addEventListener('playing', () => {
        loadingSpinner.classList.add('hidden'); // Hide loading spinner
      });

      // Toggle play/pause
      playPauseBtn.addEventListener('click', togglePause);
      window.addEventListener('keypress', togglePause);
      /*window.addEventListener('keypress', (e) =>
        videoPlayer.paused ? videoPlayer.play() : videoPlayer.pause()
      );*/

      // When video ends
      videoPlayer.addEventListener('ended', () => {
        isPaused = true;
        playIcon.style.display = 'inline';
        pauseIcon.style.display = 'none';
        playPauseText.textContent = 'Play';
        if (animationFrameId) {
          videoPlayer.cancelVideoFrameCallback(animationFrameId);
          animationFrameId = null;
        }
      });

      // Log current angle
      logAngleBtn.addEventListener('click', () => {
        if (currentAngle !== null) {
          anglesLog.push({
            angle: currentAngle,
            releaseAngle: currentReleaseAngle,
            timestamp: videoPlayer.currentTime.toFixed(2),
          });
          updateAnglesLogDisplay();
        }
      });

      // Reset video and state
      resetBtn.addEventListener('click', () => {
        stopCamera(); // Stop camera stream on reset
        toggleCameraBtn.style.display = 'none';
        if (videoPlayer.src) {
          URL.revokeObjectURL(videoPlayer.src);
        }
        videoPlayer.src = '';
        anglesLog = [];
        currentAngle = null;
        currentAngleDisplay.textContent = 'N/A';
        isPaused = true;
        updateAnglesLogDisplay();
        toggleControlsVisibility(false); // Hide controls
        ctx.clearRect(0, 0, videoCanvas.width, videoCanvas.height); // Clear canvas
        if (animationFrameId) {
          videoPlayer.cancelVideoFrameCallback(animationFrameId);
          animationFrameId = null;
        }
        playIcon.style.display = 'inline';
        pauseIcon.style.display = 'none';
        playPauseText.textContent = 'Play';
      });

      // Download button (with disclaimer)
      downloadBtn.addEventListener('click', () => {
        // This function serves as a placeholder.
        // Real-time video re-encoding with overlaid annotations directly in the browser
        // is a highly resource-intensive and complex task. It typically requires:
        // 1. Capturing each canvas frame as an image (e.g., using toDataURL or OffscreenCanvas).
        // 2. Using a client-side video encoding library (like ffmpeg.wasm) to compile these frames
        //    into a new video file, which is a very large library and adds significant complexity.
        // 3. Alternatively, sending all frames or the original video to a server for processing.
        // Due to these limitations, this client-side demo only shows live annotations.
        const messageBox = document.createElement('div');
        messageBox.className =
          'fixed inset-0 bg-gray-900 bg-opacity-75 flex items-center justify-center z-50';
        messageBox.innerHTML = `
                <div class="bg-gray-800 p-6 rounded-lg shadow-xl text-center max-w-sm">
                    <h3 class="text-xl font-bold text-blue-400 mb-4">Feature Information</h3>
                    <p class="text-gray-300 mb-6">
                        Downloading the annotated video is not directly supported client-side due to browser limitations for video re-encoding. This feature would typically require server-side processing or a complex client-side video encoding library (like ffmpeg.wasm). The annotations are shown live on the video.
                    </p>
                    <button id="close-message-box" class="bg-blue-600 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded-full">
                        Got It!
                    </button>
                </div>
            `;
        document.body.appendChild(messageBox);

        document
          .getElementById('close-message-box')
          .addEventListener('click', () => {
            document.body.removeChild(messageBox);
          });
      });

      // Toggle instructions visibility
      toggleInstructionsBtn.addEventListener('click', () => {
        const isHidden = instructionsContent.classList.toggle('hidden');
        if (isHidden) {
          chevronIcon.innerHTML = '<path d="m9 18 6-6-6-6"/>'; // ChevronRight
        } else {
          chevronIcon.innerHTML = '<path d="m6 9 6 6 6-6"/>'; // ChevronDown
        }
      });

      // --- Initialization ---
      window.onload = function () {
        initializePose(); // Initialize MediaPipe Pose when the window loads
        updateAnglesLogDisplay(); // Initialize log display
        toggleControlsVisibility(false); // Hide controls initially
      };
    </script>
  </body>
</html>
